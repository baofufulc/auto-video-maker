<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>AIæƒ…æ„ŸçŸ­è§†é¢‘ç”Ÿæˆå™¨ v2</title>
<style>
  body {
    margin: 0;
    padding: 0;
    font-family: "Microsoft YaHei", sans-serif;
    background: #000;
    color: white;
    text-align: center;
  }
  h2 {
    margin-top: 20px;
  }
  textarea {
    width: 90%;
    height: 100px;
    font-size: 16px;
    padding: 10px;
    border-radius: 8px;
    border: none;
    resize: none;
    outline: none;
  }
  button {
    margin-top: 10px;
    background: linear-gradient(45deg, #ff416c, #ff4b2b);
    color: white;
    border: none;
    border-radius: 8px;
    padding: 10px 20px;
    font-size: 16px;
  }
  .video-container {
    position: relative;
    display: inline-block;
    margin-top: 20px;
  }
  video {
    width: 90%;
    border-radius: 10px;
    filter: blur(4px) brightness(0.7);
  }
  .subtitle {
    position: absolute;
    bottom: 60px;
    width: 100%;
    text-align: center;
    font-size: 22px;
    font-weight: bold;
    color: white;
    text-shadow: 2px 2px 6px black;
    animation: fade 1.5s ease-in-out;
  }
  @keyframes fade {
    0% {opacity: 0;}
    50% {opacity: 1;}
    100% {opacity: 0;}
  }
  a {
    display: none;
    color: #4caf50;
  }
</style>
</head>
<body>
  <h2>ğŸ¬ æŠ–éŸ³é£æ ¼Â·åŠ¨æ€å­—å¹•è‡ªåŠ¨è§†é¢‘ç”Ÿæˆå™¨</h2>
  <p>è¾“å…¥ä½ çš„æ–‡å­—ï¼Œè‡ªåŠ¨ç”Ÿæˆå¸¦è¯­éŸ³ã€å­—å¹•å’ŒèƒŒæ™¯çš„çŸ­è§†é¢‘</p>

  <textarea id="textInput" placeholder="ä¾‹å¦‚ï¼šæˆ‘æ‹¼å‘½æŒ£é’±ï¼Œå› ä¸ºæˆ‘æ²¡æœ‰èƒŒæ™¯ï¼Œæ²¡æœ‰ä¾é ã€‚"></textarea><br>
  <button id="generateBtn">ç”Ÿæˆè§†é¢‘</button>

  <div class="video-container">
    <video id="preview" controls></video>
    <div id="subtitle" class="subtitle"></div>
  </div>
  <br>
  <a id="downloadLink">â¬‡ï¸ ä¸‹è½½è§†é¢‘</a>

  <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.12.6/dist/ffmpeg.min.js"></script>
  <script>
    const btn = document.getElementById('generateBtn');
    const preview = document.getElementById('preview');
    const subtitle = document.getElementById('subtitle');
    const link = document.getElementById('downloadLink');

    const backgrounds = [
      "https://cdn.pixabay.com/video/2023/03/09/153024-805776398_tiny.mp4",
      "https://cdn.pixabay.com/video/2020/04/14/36155-404791853_tiny.mp4",
      "https://cdn.pixabay.com/video/2020/03/02/32859-396660571_tiny.mp4"
    ];
    const music = "https://cdn.pixabay.com/download/audio/2022/03/15/audio_8e8f8f8a14.mp3?filename=soft-piano-ambient-14147.mp3";

    btn.onclick = async () => {
      const text = document.getElementById('textInput').value.trim();
      if (!text) return alert("è¯·è¾“å…¥æ–‡å­—");

      const bgUrl = backgrounds[Math.floor(Math.random() * backgrounds.length)];

      const synth = window.speechSynthesis;
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'zh-CN';
      utter.rate = 1;
      const voice = synth.getVoices().find(v => v.lang === 'zh-CN');
      if (voice) utter.voice = voice;

      // æ‹†å­—å¹•
      const segments = text.match(/.{1,8}/g) || [text];
      let index = 0;

      // å¯åŠ¨è¯­éŸ³å½•åˆ¶
      const audioCtx = new AudioContext();
      const dest = audioCtx.createMediaStreamDestination();
      const recorder = new MediaRecorder(dest.stream);
      const chunks = [];

      recorder.ondataavailable = e => chunks.push(e.data);
      recorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'audio/mp3' });
        const audioData = new Uint8Array(await blob.arrayBuffer());
        await mergeVideo(bgUrl, audioData);
      };

      recorder.start();
      synth.speak(utter);

      // åŠ¨æ€å­—å¹•
      const showNextSubtitle = () => {
        if (index < segments.length) {
          subtitle.innerText = segments[index++];
          subtitle.style.opacity = 1;
          setTimeout(() => {
            subtitle.style.opacity = 0;
            showNextSubtitle();
          }, 1200);
        } else {
          subtitle.innerText = "";
        }
      };
      showNextSubtitle();

      utter.onend = () => recorder.stop();
    };

    async function mergeVideo(videoUrl, audioBytes) {
      const { createFFmpeg, fetchFile } = FFmpeg;
      const ffmpeg = createFFmpeg({ log: false });
      await ffmpeg.load();

      const videoArray = new Uint8Array(await (await fetch(videoUrl)).arrayBuffer());
      const musicArray = new Uint8Array(await (await fetch(music)).arrayBuffer());

      ffmpeg.FS("writeFile", "bg.mp4", videoArray);
      ffmpeg.FS("writeFile", "voice.mp3", audioBytes);
      ffmpeg.FS("writeFile", "bgm.mp3", musicArray);

      await ffmpeg.run("-i", "bg.mp4", "-i", "voice.mp3", "-i", "bgm.mp3", "-filter_complex", "amix=inputs=2:duration=shortest", "-shortest", "-c:v", "copy", "out.mp4");

      const output = ffmpeg.FS("readFile", "out.mp4");
      const videoBlob = new Blob([output.buffer], { type: "video/mp4" });
      const videoURL = URL.createObjectURL(videoBlob);

      preview.src = videoURL;
      link.href = videoURL;
      link.download = "emotion-video.mp4";
      link.style.display = "block";
    }
  </script>
</body>
</html>
